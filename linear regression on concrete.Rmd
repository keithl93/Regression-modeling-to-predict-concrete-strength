---
title: "Concrete Strength"
author: "Keith Kwanghyun Lee"
date: "2022-12-14"
output:
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```





```{r include=FALSE}
require(faraway)
library(tidyverse)
library(MASS) #boxcox
library(tidyverse)
library(faraway)
```

# Introduction

## Decide on the research question

Fit a linear regression model to assess the effect of predictors on the Concrete Strength, and make a prediction about Strength given specified values of the predictors.


## Determine the response variable and potential predictors 

The response variable: Strength of concrete (Continuous)

Potential predictors are :
  
1. Blast Furnace Slag(BFS)
Slag Produced in Blast Furnace

2. Fly Ash(FA)
Amount of ash produced

3. Water
Amount of water required

4. Superplasticizer
rigidity of cement after drying

5. Coarse Aggregate(CA)
The coarse nature of the cement particles

6. Fine Aggregate(FAA)
Fineness of the cement

7. Age
Age or time before it needs repairing

8.Cement
Cement
# Analysis 

## Data Preparation and Cleaning 

### Import data

```{r}

data <- read_csv("C:/Users/khlee/OneDrive/Documents/GWANGJAAA/NYU/Fall22/Regression/concrete_data.csv")


names(data)[2] <- 'BFS' # Name Change
names(data)[3] <- 'FA' # Name Change
names(data)[6] <- 'CA' # Name Change
names(data)[7] <- 'FAA' # Name Change

ran <- sample(1:nrow(data),0.8*nrow(data))
data_tr <- data[ran,]
data_tt <- data[-ran,]

data %>% 
  head(3)
```

We change some predictors name, such as:
Blast Furnace Slag to BFS.
Fly Ash to FAA
Coarse Aggregate to CA
Fine Aggregate to FA




### Solve the missing data issue

```{r}
sum(is.na(data))
```

There is no missing value in this dataset. 
Our data is redy to be analyzed

## Exploratory Data Analysis

### Summary statistics

```{r include = F}
dim(data)
dim(data_tr)
```

This dataset has 1030 observations and 9 Variables(8 Predictors with 1 Response)

```{r}
summary(data)
```

### Univariate plots

```{r}
par(mfrow = c(2,2))
hist(data_tr$Cement)
hist(data_tr$BFS)
hist(data_tr$FA)
hist(data_tr$Water)
hist(data_tr$Superplasticizer)
hist(data_tr$CA) 
hist(data_tr$FAA)
hist(data_tr$Age)
hist(data_tr$Strength)
```

Description: In general, **Water**, **Ca**, **Faa**, and **strength** follow normal distribution; The distribution of **Cement**,**FA**, **BFS**, **Water** and **superplasticizer** is right skewed; 

## plots for multiple variables 

```{r}
par(mfrow = c(1,1))
plot(data_tr$Cement, data_tr$Strength)
plot(data_tr$BFS,data_tr$Strength)
plot(data_tr$FA,data_tr$Strength)
plot(data_tr$Water,data_tr$Strength)
plot(data_tr$Superplasticizer,data_tr$Strength)
plot(data_tr$CA,data_tr$Strength)
plot(data_tr$FAA,data_tr$Strength)
plot(data_tr$Age,data_tr$Strength)
```
```{r}
library ("gridExtra")
require(ggplot2)  
p1 <- ggplot(data_tr, aes(Cement, Strength)) + geom_point() + stat_smooth(method="lm")
p2 <- ggplot(data_tr, aes(BFS, Strength)) + geom_point() + stat_smooth(method="lm")
p3 <- ggplot(data_tr, aes(FA, Strength)) + geom_point() +stat_smooth(method="lm")
p4 <- ggplot(data_tr, aes(Water, Strength)) + geom_point() + stat_smooth( method="lm")
p5 <- ggplot(data_tr, aes(Superplasticizer, Strength)) + geom_point() + stat_smooth(method="lm")
p6 <- ggplot(data_tr, aes(CA, Strength)) + geom_point()+ stat_smooth( method="lm") 
grid.arrange(p1, p2, p3, p4, p5, p6, nrow = 2)

```
We can learn that linear trends among **cement** and **ca** to **strength**. Thus, trying to fit a linear model is reasonable.



## Inference: hypothesis testing 

### test one predictor, FAA
```{r}
full <- lm(Strength ~., data_tr) # Full Model
summary(full)
wofaa <- lm(Strength ~ .-FAA,
                  data_tr)

anova(wofaa, full)

```
P value is large, so we fail to reject the null hypothesis that Fine Aggregate = 0 

### test one predictor, CA
```{r}
woca <- lm(Strength ~ .-CA,
                  data_tr)
anova(woca, full)
```
P value is smaller than 0.05, so we reject the null hypothesis that Coarse Aggregate = 0 


### test a group of variables:
```{r}
wocanfaa <- lm(Strength ~ Cement + BFS + FA + Water +
                    Superplasticizer + Age,data_tr)
anova(wocanfaa, full)
```
P value is large, so we so we fail to reject the null hypothesis that Coarse Aggregate and Fine Aggregate = 0, which matched with our BIC model.

# Model selection

```{r}
require(leaps)
b <- regsubsets(Strength~.,data=data_tr)

rs  = summary(b)
rs$which
n = 824

AIC <- n*log((rs$rss)/n) + (2:9)*2
plot(AIC ~ I(1:8), ylab="AIC", xlab="Number of Predictors")

which.min(AIC)

BIC <- n*log(rs$rss/n) + (2:9)*log(n)
plot(BIC ~ I(1:8), ylab="BIC", xlab="Number of Predictors")
which.min(BIC)

wocanfaa <- lm(Strength ~ Cement + BFS + FA + Water +
                    Age,data_tr)
```
Although our AIC and BIC do not match, we chose to continue with BIC.



### Inference: Confidence Intervals
# 95% confidence interval for BIC model
```{r}
confint(wocanfaa)
```
0 is not in the any confidence interval for all predictors, this indicates that the null hypothesis that beta = 0 for any of them would be rejected at alpha = 5% level.

# 95% confidence interval for full model
```{r}
confint(full)
```
0 is in the confidence interval of CA and FAA, this indicates that the null hypothesis that beta = 0 for them would be rejected at alpha = 5% level. 
## Both of the confidence interval at 95% supports our model selection

# 90% confidence interval for BIC model
```{r}
confint(wocanfaa, level = 0.9)
```

We calculated 90 percent confidence interval for beta, 0 is not included in any intervals, we can reject null hypothesis for any predictors at alpha = 0.9
## They are significant at 0.9 level

# 90% confidence interval for full model
```{r}
confint(full, level = .9)
```
0 is in the confidence interval of CA and FAA

Since our research is based on 95% level, contradiction made between 95% and 90% confidence interval does not support our proceduire but it does not discourage our process either.  


## Diagnostics

### Constant Variance
```{r}
plot(fitted(wocanfaa), residuals(wocanfaa), xlab = "Fitted", ylab = "Residuals")
abline(h=0)
resi1 <- residuals(wocanfaa)
yhat1 <- fitted(wocanfaa)
summary(yhat1)
var.test(residuals(wocanfaa)[yhat1>36.15], residuals(wocanfaa)[yhat1<36.15])

```
Our constant variance test shows that there is significant difference between constants. In other words, the null hypothesis, variance is constant, is rejected.


### normal errors
```{r}
qqnorm(residuals(wocanfaa), ylab = "Residuals", main = "")
qqline(residuals(wocanfaa))
shapiro.test(residuals(wocanfaa))
qqnorm(rstandard(wocanfaa))
abline(0,1)
shapiro.test(residuals(wocanfaa))
```
We have our P values less than 0.05. The null hypothesis, residuals are normal, is rejected.  

### Leverages and Outliers
```{r}
# leverage points
n <- nrow(data_tr)
hatv <- hatvalues(wocanfaa)
p <- sum(hatv)
which(hatv > 2*p/n)
```

# get outlier
```{r}
n <- nrow(data_tr)
stud <- rstudent(wocanfaa)
stud[which.max(abs(stud))]

qt(1-.05/(n*2),n-p-1)
which(abs(stud) > qt(1-.05/(n*2),n-p-1))
```
No outlier detected

```{r}
x <- model.matrix(wocanfaa)[,-1]
vif(x)
max(vif(x))
```
Passed

### Serial Correlation, Durbin Wtason test
```{r}
library(lmtest)
dwtest(wocanfaa)
```

Test Statistics with 2.0514 and P is greater than 0.05, fail to reject null


From previous diagnostics, we conclude that the transformation is needed

## Transformation
```{r}
boxcox(wocanfaa, plotit = T, lambda = seq(0.5,0.9,by = 0.1))
```
We see that the interval is approximately from 0.61 to 0.81, we can choose 0.7 as our lambda value
```{r}
trans=(lm(Strength^0.71 ~ Cement + Water + BFS + FA + Age, data_tr))
#trans = lm(log(Strength) ~  Cement + Water + Superplasticizer + BFS + FA + Age, data)
#trans = lm(Strength~ polym(Cement, Water, Superplasticizer, BFS, FA, Age,degree = 2), data)
```




## 2nd round of diagnostic

### Constant Variance #2
```{r}
plot(fitted(trans), residuals(trans), xlab = "Fitted", ylab = "Residuals")
abline(h=0)
resi1 <- residuals(trans)
yhat1 <- fitted(trans)


var.test(residuals(trans)[yhat1>mean(yhat1)], residuals(trans)[yhat1<mean(yhat1)])

```
Our constant variance test shows thet there is significant difference between constants. In other words, the null hypothesis, variance is constant, is rejected.


### normal errors #2
```{r}
qqnorm(residuals(trans), ylab = "Residuals", main = "")
qqline(residuals(trans))
abline(0,1, col ="red")
shapiro.test(residuals(trans))

```
We have our P values less than 0.05. The null hypothesis, residuals are normal, is rejected.  Test failed

### Leverages and Outliers #2
```{r}

n <- nrow(data_tr)
hatv <- hatvalues(trans)
p <- sum(hatv)
which(hatv > 2*p/n)



n <- nrow(data_tr)
stud <- rstudent(trans)
stud[which.max(abs(stud))]

qt(1-.05/(n*2),n-p-1)
which(abs(stud) > qt(1-.05/(n*2),n-p-1))
```
Still, no outliers detected

### Serial Correlation, Durbin Watson test #2
```{r}
library(lmtest)
dwtest(trans)
```
# p-value is greater than 0.05,test passed

```{r}
x <- model.matrix(trans)[,-1]
vif(x)
max(vif(x))
```
Passed


## Some conclusion...


```{r}
###prediction
trans_final=(lm(Strength^0.7 ~ Cement + Water + Superplasticizer + BFS + FA + Age, data_tt))
x <- model.matrix(trans_final)
x0 <- apply(x,2,median) # get median characteristics

pred1 <- predict(trans_final, data.frame(t(x0)), interval = "p")
pred1
confident1 <- predict(trans_final, data.frame(t(x0)), interval = "c")
confident1
```

The prediction is based on the model that could not pass the diagnostic, our transformation failed.
It is not a good model to predict the strength of concrete. 




